{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import inflect\n",
    "import re\n",
    "import time\n",
    "# next we can import some sklearn libraries to start working with stuff\n",
    "## transformers and pipline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "## model selectors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV, GroupKFold, GroupShuffleSplit\n",
    "## models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "## feature extractors\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from average_word_length_extractor import AverageWordLengthExtractor\n",
    "from question_extractor import QuestionExtractor\n",
    "from int_to_words_extractor import NumberStringExtractor\n",
    "from greeting_extractor import GreetingExtractor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from text_preprocessor import TextPreprocessor\n",
    "from sentiment_extractor import SentimentExtractor\n",
    "from ner_extractor import NERExtractor\n",
    "# save model\n",
    "from sklearn.externals import joblib\n",
    "# deep learning models\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, TimeDistributed, Dense, Bidirectional, Input, Flatten\n",
    "import keras.backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_files = glob.glob('../data/data_v1/TrainCSV_Updated/*.csv')\n",
    "train = pd.concat([pd.read_csv(fp).assign(train_set=re.split('_|, ',os.path.basename(fp))[0]) for fp in train_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stringList</th>\n",
       "      <th>speakerID</th>\n",
       "      <th>semanticType</th>\n",
       "      <th>leading</th>\n",
       "      <th>Symptom</th>\n",
       "      <th>PMH</th>\n",
       "      <th>MEDS</th>\n",
       "      <th>ALLG</th>\n",
       "      <th>FAMHx</th>\n",
       "      <th>lifestyle</th>\n",
       "      <th>...</th>\n",
       "      <th>GS4089</th>\n",
       "      <th>GS4090</th>\n",
       "      <th>GS4091</th>\n",
       "      <th>GS4092</th>\n",
       "      <th>GS4093</th>\n",
       "      <th>GS4094</th>\n",
       "      <th>GS4095</th>\n",
       "      <th>supportProvision</th>\n",
       "      <th>stringedQuestion</th>\n",
       "      <th>train_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so why don't you tell me what brings you here ...</td>\n",
       "      <td>doctor</td>\n",
       "      <td>openQuestion</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070285</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>-0.020626</td>\n",
       "      <td>0.031314</td>\n",
       "      <td>-0.003403</td>\n",
       "      <td>-0.006069</td>\n",
       "      <td>-0.008571</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so I've been having this kind of random fast w...</td>\n",
       "      <td>patient</td>\n",
       "      <td>statement</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035766</td>\n",
       "      <td>-0.009635</td>\n",
       "      <td>0.036159</td>\n",
       "      <td>-0.019223</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.056419</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okay that's pretty fast</td>\n",
       "      <td>doctor</td>\n",
       "      <td>statement</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130121</td>\n",
       "      <td>-0.033890</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.019991</td>\n",
       "      <td>0.093138</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 4142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          stringList speakerID  semanticType  \\\n",
       "0  so why don't you tell me what brings you here ...    doctor  openQuestion   \n",
       "1  so I've been having this kind of random fast w...   patient     statement   \n",
       "2                            okay that's pretty fast    doctor     statement   \n",
       "\n",
       "  leading Symptom PMH MEDS ALLG FAMHx lifestyle    ...        GS4089  \\\n",
       "0      no      no  no   no   no    no        no    ...      0.070285   \n",
       "1      no     yes  no   no   no    no        no    ...      0.035766   \n",
       "2      no      no  no   no   no    no        no    ...      0.130121   \n",
       "\n",
       "     GS4090    GS4091    GS4092    GS4093    GS4094    GS4095  \\\n",
       "0  0.009144 -0.020626  0.031314 -0.003403 -0.006069 -0.008571   \n",
       "1 -0.009635  0.036159 -0.019223  0.011710  0.054135  0.056419   \n",
       "2 -0.033890  0.023881  0.002090  0.000385  0.019991  0.093138   \n",
       "\n",
       "  supportProvision stringedQuestion  train_set  \n",
       "0               no               no          3  \n",
       "1               no               no          3  \n",
       "2               no               no          3  \n",
       "\n",
       "[3 rows x 4142 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert yes to True(1) and no to False(0)\n",
    "train = train.replace(to_replace={'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove train_set columns\n",
    "train.drop(['train_set'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features over which we have to predict\n",
    "prediction_columns = ['stringedQuestion',\n",
    "                   'leading', 'Symptom', 'PMH', 'MEDS', 'ALLG', 'FAMHx', 'lifestyle',\n",
    "                   'pysch', 'SOCHx', 'sexualHistory', 'substanceUse', 'PE', 'FORM',\n",
    "                   'supportProvision', 'transition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract doctor interactions\n",
    "train = train.loc[train.speakerID == 'doctor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get case values\n",
    "cases = train['case_ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nas for now\n",
    "train.dropna(inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stringedQuestion: 2.496%\n",
      "leading: 0.263%\n",
      "Symptom: 20.297%\n",
      "PMH: 4.643%\n",
      "MEDS: 1.239%\n",
      "ALLG: 0.671%\n",
      "FAMHx: 3.735%\n",
      "lifestyle: 1.562%\n",
      "pysch: 2.216%\n",
      "SOCHx: 3.548%\n",
      "sexualHistory: 0.475%\n",
      "substanceUse: 2.496%\n",
      "PE: 13.531%\n",
      "FORM: 11.104%\n",
      "supportProvision: 3.311%\n",
      "transition: 8.124%\n"
     ]
    }
   ],
   "source": [
    "# check the balance for each prediction feature\n",
    "for n,i in enumerate(prediction_columns):\n",
    "    balance = train.loc[:, train.columns == prediction_columns[n]][i].value_counts()[1] / train.shape[0]\n",
    "    print('%s: %0.3f%%'%(i, balance*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "## count vectorizer\n",
    "### word level\n",
    "ngram_count_word = CountVectorizer(ngram_range=(1, 3), analyzer='word', token_pattern=r'\\w{1,}', max_features= 2000)\n",
    "### char level\n",
    "ngram_count_char = CountVectorizer(ngram_range=(1, 2), analyzer='char')\n",
    "## tf idf vectorizer\n",
    "### word level\n",
    "tf_idf_word = TfidfVectorizer(ngram_range=(1, 3), analyzer='word', token_pattern=r'\\w{1,}', max_features= 2000)\n",
    "### char level\n",
    "tf_idf_char = TfidfVectorizer(ngram_range=(1, 2), analyzer='char')\n",
    "text_preprocessor = TextPreprocessor()\n",
    "avg_word = AverageWordLengthExtractor()\n",
    "question_ex = QuestionExtractor()\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "numberstring= NumberStringExtractor()\n",
    "std_scaler = StandardScaler()\n",
    "greeting_ex = GreetingExtractor()\n",
    "sent_extractor = SentimentExtractor()\n",
    "ner_extractor = NERExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert numbers to text\n",
    "num_to_str = ColumnTransformer([\n",
    "    ('numberstring', numberstring, 3)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# original feature encoders\n",
    "original_feat = ColumnTransformer([\n",
    "    ('avg_word', avg_word, 0),\n",
    "    ('question', question_ex, 0),\n",
    "    ('greeting', greeting_ex, 0),\n",
    "    ('sentiment', sent_extractor, 0),\n",
    "    ('ner', ner_extractor, 0)\n",
    "], remainder = 'passthrough')\n",
    "\n",
    "# text preprocessor\n",
    "text_pre = ColumnTransformer([\n",
    "    ('text_preprocessor', text_preprocessor, 0)\n",
    "], remainder= 'passthrough')\n",
    "\n",
    "# text encoders\n",
    "encoders = ColumnTransformer([\n",
    "    ('ngram_char', ngram_count_char, 0),\n",
    "    ('ngram_word', ngram_count_word, 0),\n",
    "    ('tdf_idf_char', tf_idf_char, 0),\n",
    "    ('tdf_idf_word', tf_idf_char, 0)\n",
    "], remainder = 'passthrough')\n",
    "\n",
    "# one hot encoding\n",
    "one_hot = ColumnTransformer([\n",
    "    ('one_hot', one_hot_encoder, ['semanticType'])\n",
    "], remainder = 'passthrough')\n",
    "\n",
    "# text pipeline\n",
    "text_features = Pipeline([\n",
    "    ('num_to_str', num_to_str),\n",
    "    ('original_feat', original_feat),\n",
    "    ('text_pre', text_pre),\n",
    "    ('encoders', encoders)\n",
    "])\n",
    "\n",
    "# preprocessing\n",
    "preprocess = Pipeline([\n",
    "    ('one_hot_encoder', one_hot),\n",
    "    ('text_feat', text_features),\n",
    "    ('std_scaler', std_scaler)\n",
    "])\n",
    "\n",
    "# ml pipeline\n",
    "ml_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocess),\n",
    "    ('model', LGBMClassifier(n_estimators = 100, n_jobs = -1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model dictionary\n",
    "models = {}\n",
    "# select columns by data\n",
    "X_train = train.drop(prediction_columns, axis=1)\n",
    "unusable_columns = ['speakerID', 'case_ID']\n",
    "X_train = X_train.drop(unusable_columns, axis=1)\n",
    "# shuffle split generator\n",
    "group_shuffle_split = GroupShuffleSplit(n_splits=1, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process X_train\n",
    "X_train_processed = preprocess.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = []\n",
    "for i in np.unique(cases):\n",
    "    A = np.zeros(shape = (np.unique(cases, return_counts=True)[1].max(), X_train_processed.shape[1]))\n",
    "    A[:X_train_processed[cases == i].shape[0], :X_train_processed[cases == i].shape[1]] = X_train_processed[cases == i]\n",
    "    input_x.append(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = np.array(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_y = []\n",
    "y_trains = train.loc[:, train.columns == prediction_columns[2]]\n",
    "for i in np.unique(cases):\n",
    "    A = np.zeros(shape = (np.unique(cases, return_counts=True)[1].max(), 1))\n",
    "    A[:y_train[cases == i].shape[0], ] = y_train[cases == i]\n",
    "    input_y.append(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_y = np.array(input_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LSTM\n",
    "# model = Sequential()\n",
    "# model.add(Bidirectional(LSTM(100, return_sequences=True,dropout=0.50), input_shape=(input_x.shape[1], input_x.shape[2]),merge_mode='concat'))\n",
    "# model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "# model.add(TimeDistributed(Flatten()))\n",
    "# model.add(Dense(100,activation='relu'))\n",
    "# model.add(Dense(1,activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', recall_m, precision_m, f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(input_x.shape[1], input_x.shape[2],))\n",
    "model = Bidirectional(LSTM(100, return_sequences=True,dropout=0.50),merge_mode='concat')(input)\n",
    "model = TimeDistributed(Dense(100,activation='relu'))(model)\n",
    "model = TimeDistributed(Flatten())(model)\n",
    "model = Dense(100,activation='relu')(model)\n",
    "output = Dense(1,activation='sigmoid')(model)\n",
    "model = Model(input,output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', recall_m, precision_m, f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # main model\n",
    "# input = Input(shape=(input_x.shape[1], input_x.shape[2],))\n",
    "# model =  Bidirectional (LSTM (100,return_sequences=True,dropout=0.50),merge_mode='concat')(input)\n",
    "# model = TimeDistributed(Dense(100,activation='relu'))(model)\n",
    "# model = Flatten()(model)\n",
    "# model = Dense(100,activation='relu')(model)\n",
    "# output = Dense(1,activation='sigmoid')(model)\n",
    "# model = Model(input,output)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', recall_m, precision_m, f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 202, 7774)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 202, 200)          6300000   \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 202, 100)          20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 202, 100)          0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 202, 100)          10100     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 202, 1)            101       \n",
      "=================================================================\n",
      "Total params: 6,330,301\n",
      "Trainable params: 6,330,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "68/68 [==============================] - 32s 475ms/step - loss: 0.4615 - acc: 0.9490 - recall_m: 0.0403 - precision_m: 0.0171 - f1_m: 0.0224 - val_loss: 0.1994 - val_acc: 0.9783 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/20\n",
      "68/68 [==============================] - 18s 269ms/step - loss: 0.2276 - acc: 0.9843 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.1165 - val_acc: 0.9783 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/20\n",
      "68/68 [==============================] - 18s 265ms/step - loss: 0.0837 - acc: 0.9843 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.0544 - val_acc: 0.9783 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 4/20\n",
      "68/68 [==============================] - 18s 267ms/step - loss: 0.0296 - acc: 0.9843 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.0482 - val_acc: 0.9783 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 5/20\n",
      "68/68 [==============================] - 18s 266ms/step - loss: 0.0242 - acc: 0.9843 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: 0.0445 - val_acc: 0.9783 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 6/20\n",
      "68/68 [==============================] - 18s 258ms/step - loss: 0.0200 - acc: 0.9845 - recall_m: 0.0082 - precision_m: 0.4706 - f1_m: 0.0161 - val_loss: 0.0429 - val_acc: 0.9799 - val_recall_m: 0.0756 - val_precision_m: 1.0000 - val_f1_m: 0.1406\n",
      "Epoch 7/20\n",
      "68/68 [==============================] - 18s 260ms/step - loss: 0.0168 - acc: 0.9854 - recall_m: 0.0667 - precision_m: 1.0000 - f1_m: 0.1239 - val_loss: 0.0429 - val_acc: 0.9829 - val_recall_m: 0.2095 - val_precision_m: 1.0000 - val_f1_m: 0.3444\n",
      "Epoch 8/20\n",
      "68/68 [==============================] - 18s 260ms/step - loss: 0.0146 - acc: 0.9881 - recall_m: 0.2416 - precision_m: 1.0000 - f1_m: 0.3831 - val_loss: 0.0425 - val_acc: 0.9865 - val_recall_m: 0.3619 - val_precision_m: 1.0000 - val_f1_m: 0.5195\n",
      "Epoch 9/20\n",
      "68/68 [==============================] - 18s 261ms/step - loss: 0.0129 - acc: 0.9921 - recall_m: 0.5230 - precision_m: 0.9763 - f1_m: 0.6700 - val_loss: 0.0421 - val_acc: 0.9879 - val_recall_m: 0.5039 - val_precision_m: 0.8799 - val_f1_m: 0.6329\n",
      "Epoch 10/20\n",
      "68/68 [==============================] - 18s 259ms/step - loss: 0.0109 - acc: 0.9972 - recall_m: 0.8269 - precision_m: 0.9855 - f1_m: 0.8963 - val_loss: 0.0422 - val_acc: 0.9882 - val_recall_m: 0.5569 - val_precision_m: 0.8333 - val_f1_m: 0.6634\n",
      "Epoch 11/20\n",
      "68/68 [==============================] - 18s 264ms/step - loss: 0.0090 - acc: 0.9988 - recall_m: 0.9512 - precision_m: 0.9723 - f1_m: 0.9613 - val_loss: 0.0427 - val_acc: 0.9887 - val_recall_m: 0.5795 - val_precision_m: 0.8382 - val_f1_m: 0.6796\n",
      "Epoch 12/20\n",
      "68/68 [==============================] - 18s 268ms/step - loss: 0.0069 - acc: 0.9996 - recall_m: 0.9866 - precision_m: 0.9904 - f1_m: 0.9884 - val_loss: 0.0434 - val_acc: 0.9879 - val_recall_m: 0.5927 - val_precision_m: 0.7792 - val_f1_m: 0.6698\n",
      "Epoch 13/20\n",
      "68/68 [==============================] - 18s 272ms/step - loss: 0.0049 - acc: 0.9997 - recall_m: 0.9960 - precision_m: 0.9883 - f1_m: 0.9921 - val_loss: 0.0439 - val_acc: 0.9873 - val_recall_m: 0.6060 - val_precision_m: 0.7436 - val_f1_m: 0.6655\n",
      "Epoch 14/20\n",
      "68/68 [==============================] - 18s 263ms/step - loss: 0.0034 - acc: 0.9997 - recall_m: 1.0000 - precision_m: 0.9826 - f1_m: 0.9912 - val_loss: 0.0449 - val_acc: 0.9868 - val_recall_m: 0.6325 - val_precision_m: 0.7111 - val_f1_m: 0.6675\n",
      "Epoch 15/20\n",
      "68/68 [==============================] - 18s 264ms/step - loss: 0.0021 - acc: 0.9999 - recall_m: 1.0000 - precision_m: 0.9913 - f1_m: 0.9956 - val_loss: 0.0462 - val_acc: 0.9862 - val_recall_m: 0.6193 - val_precision_m: 0.6955 - val_f1_m: 0.6532\n",
      "Epoch 16/20\n",
      "68/68 [==============================] - 18s 263ms/step - loss: 0.0013 - acc: 1.0000 - recall_m: 1.0000 - precision_m: 1.0000 - f1_m: 1.0000 - val_loss: 0.0481 - val_acc: 0.9873 - val_recall_m: 0.6193 - val_precision_m: 0.7414 - val_f1_m: 0.6718\n",
      "Epoch 17/20\n",
      "68/68 [==============================] - 18s 264ms/step - loss: 8.2059e-04 - acc: 1.0000 - recall_m: 1.0000 - precision_m: 1.0000 - f1_m: 1.0000 - val_loss: 0.0497 - val_acc: 0.9868 - val_recall_m: 0.6193 - val_precision_m: 0.7176 - val_f1_m: 0.6623\n",
      "Epoch 18/20\n",
      "68/68 [==============================] - 18s 263ms/step - loss: 5.7869e-04 - acc: 1.0000 - recall_m: 1.0000 - precision_m: 1.0000 - f1_m: 1.0000 - val_loss: 0.0509 - val_acc: 0.9871 - val_recall_m: 0.6325 - val_precision_m: 0.7222 - val_f1_m: 0.6722\n",
      "Epoch 19/20\n",
      "68/68 [==============================] - 18s 265ms/step - loss: 4.1692e-04 - acc: 1.0000 - recall_m: 1.0000 - precision_m: 1.0000 - f1_m: 1.0000 - val_loss: 0.0523 - val_acc: 0.9873 - val_recall_m: 0.6458 - val_precision_m: 0.7267 - val_f1_m: 0.6818\n",
      "Epoch 20/20\n",
      "68/68 [==============================] - 18s 271ms/step - loss: 3.0746e-04 - acc: 1.0000 - recall_m: 1.0000 - precision_m: 1.0000 - f1_m: 1.0000 - val_loss: 0.0535 - val_acc: 0.9868 - val_recall_m: 0.6458 - val_precision_m: 0.7050 - val_f1_m: 0.6725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac50d3b00>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_x, input_y, epochs=20, batch_size=16, verbose=1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
