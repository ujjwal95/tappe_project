{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import inflect\n",
    "import re\n",
    "import time\n",
    "# next we can import some sklearn libraries to start working with stuff\n",
    "## transformers and pipline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "## model selectors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "## models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "## feature extractors\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from average_word_length_extractor import AverageWordLengthExtractor\n",
    "from question_extractor import QuestionExtractor\n",
    "from int_to_words_extractor import NumberStringExtractor\n",
    "from greeting_extractor import GreetingExtractor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from text_preprocessor import TextPreprocessor\n",
    "from sentiment_extractor import SentimentExtractor\n",
    "from ner_extractor import NERExtractor\n",
    "# model testing\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, confusion_matrix \n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score, brier_score_loss, recall_score, precision_score\n",
    "from sklearn.utils.fixes import signature\n",
    "# save model\n",
    "from sklearn.externals import joblib\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = glob.glob('../data/data_v1/TestCSV_Updated/*.csv')\n",
    "test = pd.concat([pd.read_csv(fp).assign(test_set=re.split('_|, ',os.path.basename(fp))[0]) for fp in test_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stringList</th>\n",
       "      <th>speakerID</th>\n",
       "      <th>semanticType</th>\n",
       "      <th>leading</th>\n",
       "      <th>Symptom</th>\n",
       "      <th>PMH</th>\n",
       "      <th>MEDS</th>\n",
       "      <th>ALLG</th>\n",
       "      <th>FAMHx</th>\n",
       "      <th>lifestyle</th>\n",
       "      <th>...</th>\n",
       "      <th>GS4089</th>\n",
       "      <th>GS4090</th>\n",
       "      <th>GS4091</th>\n",
       "      <th>GS4092</th>\n",
       "      <th>GS4093</th>\n",
       "      <th>GS4094</th>\n",
       "      <th>GS4095</th>\n",
       "      <th>stringedQuestion</th>\n",
       "      <th>supportProvision</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so I was wondering if you could tell me why yo...</td>\n",
       "      <td>doctor</td>\n",
       "      <td>openQuestion</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122049</td>\n",
       "      <td>-0.030231</td>\n",
       "      <td>-0.014938</td>\n",
       "      <td>0.023475</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>-0.003502</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>okay</td>\n",
       "      <td>patient</td>\n",
       "      <td>statement</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081148</td>\n",
       "      <td>-0.030529</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.026534</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>um I lost like 15 pounds just really quickly i...</td>\n",
       "      <td>patient</td>\n",
       "      <td>statement</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042242</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.018835</td>\n",
       "      <td>-0.019626</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.082543</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 4142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          stringList speakerID  semanticType  \\\n",
       "0  so I was wondering if you could tell me why yo...    doctor  openQuestion   \n",
       "1                                               okay   patient     statement   \n",
       "2  um I lost like 15 pounds just really quickly i...   patient     statement   \n",
       "\n",
       "  leading Symptom PMH MEDS ALLG FAMHx lifestyle  ...    GS4089    GS4090  \\\n",
       "0      no      no  no   no   no    no        no  ...  0.122049 -0.030231   \n",
       "1      no      no  no   no   no    no        no  ...  0.081148 -0.030529   \n",
       "2      no     yes  no   no   no    no        no  ...  0.042242  0.010893   \n",
       "\n",
       "     GS4091    GS4092    GS4093    GS4094    GS4095 stringedQuestion  \\\n",
       "0 -0.014938  0.023475 -0.004900 -0.003502  0.034194               no   \n",
       "1  0.009020  0.026534  0.000665  0.012509  0.008983               no   \n",
       "2  0.018835 -0.019626  0.010086  0.002141  0.082543               no   \n",
       "\n",
       "  supportProvision  test_set  \n",
       "0               no        10  \n",
       "1               no        10  \n",
       "2               no        10  \n",
       "\n",
       "[3 rows x 4142 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert yes to True(1) and no to False(0)\n",
    "test = test.replace(to_replace={'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove test_set columns\n",
    "test.drop(['test_set'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features over which we have to predict\n",
    "prediction_columns = ['stringedQuestion',\n",
    "                   'leading', 'Symptom', 'PMH', 'MEDS', 'ALLG', 'FAMHx', 'lifestyle',\n",
    "                   'pysch', 'SOCHx', 'sexualHistory', 'substanceUse', 'PE', 'FORM',\n",
    "                   'supportProvision', 'transition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract doctor interactions\n",
    "test = test.loc[test.speakerID == 'doctor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nas for now\n",
    "test.dropna(inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns by data\n",
    "X_test = test.drop(prediction_columns, axis=1)\n",
    "unusable_columns = ['speakerID', 'case_ID']\n",
    "X_test = X_test.drop(unusable_columns, axis=1)\n",
    "# select x and y\n",
    "y_test = test.loc[:, test.columns == prediction_columns[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stringedQuestion: 2.687%\n",
      "leading: 0.258%\n",
      "Symptom: 24.651%\n",
      "PMH: 4.961%\n",
      "MEDS: 1.240%\n",
      "ALLG: 0.724%\n",
      "FAMHx: 3.669%\n",
      "lifestyle: 1.964%\n",
      "pysch: 2.532%\n",
      "SOCHx: 2.842%\n",
      "sexualHistory: 0.207%\n",
      "substanceUse: 2.377%\n",
      "PE: 10.853%\n",
      "FORM: 12.196%\n",
      "supportProvision: 2.274%\n",
      "transition: 6.873%\n"
     ]
    }
   ],
   "source": [
    "# check the balance for each prediction feature\n",
    "for n,i in enumerate(prediction_columns):\n",
    "    balance = test.loc[:, test.columns == prediction_columns[n]][i].value_counts()[1] / y_test.shape[0]\n",
    "    print('%s: %0.3f%%'%(i, balance*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '20190406-163309-LightGBM-no-search.pkl'\n",
    "# machine learning models\n",
    "ml_pipeline = joblib.load('../model/' + file_name)\n",
    "# log file\n",
    "log = pd.read_csv('../results/log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in prediction_columns:\n",
    "    y_test = test.loc[:, test.columns == prediction_columns[n]]\n",
    "    \n",
    "    # get predictions\n",
    "    probs = ml_pipeline[i].predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    y_pred = ml_pipeline[i].predict(X_test)\n",
    "    \n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (i, classification_report(y_test, y_pred)))\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "    # confusion matrix\n",
    "    plt.subplot(1, 3, 1)\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix(y_test, y_pred), \n",
    "        index=[0, 1], \n",
    "        columns=[0, 1], \n",
    "    )\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    # roc curve\n",
    "    plt.subplot(1, 3, 2)\n",
    "    fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, '#e74c3c', label = 'AUC = %0.4f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--', color = '#34495e')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "\n",
    "    # p-r curve\n",
    "    plt.subplot(1, 3, 3)\n",
    "    average_precision = average_precision_score(y_test, preds)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, preds)\n",
    "\n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "    plt.step(recall, precision, color='#e74c3c', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='#e74c3c', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve: AP={0:0.4f}'.format(\n",
    "              average_precision))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # save model performance to log file\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    brier_score = brier_score_loss(y_test, y_pred)\n",
    "\n",
    "    log = log.append(pd.Series([file_name, '../model/' + file_name, i, accuracy, f1, recall, precision, roc_auc, average_precision, brier_score], index=log.columns), ignore_index=True)\n",
    "\n",
    "log.to_csv('../results/log.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
